\subsection{Indexed Grammars}\label{func:preliminaries-index} 

The indexed grammars were first introduced in~\cite{Aho67}. They generate the class of indexed languages which contains all context-free languages and is contained within the class of context-free languages.  A nice feature of this class of languages  is that it conserves closure properties and decidability results. In addition to the set of terminals and non terminals from the context-free grammars, the indexed grammars introduce the set of {\em index symbols}.  

In this work, we adopt the notations introduced by Hopcroft and Ullman in \cite{}. According to \cite{}, an indexed grammar is defined a 5-tuple $G = (N,T,F,P,S)$ where
\begin{itemize}
\item $N$ is a set of variables or nonterminal symbols,
\item $T$ is a set ("alphabet") of terminal symbols,
\item $F$ is a set of index symbols (indices),
\item $S \in N$  is the start symbol, and
\item $P$ is a finite set of productions.
\end{itemize}

In productions as well as in derivations of indexed grammars, a stack consisting of a string of index symbols is attached to every nonterminal symbol $A \in N$, denoted by $A[\sigma]$ ($\sigma \in F*$).  For an index stack $\sigma \in F*$ and a string $\alpha \in (N \cup T)*$ of nonterminal and terminal symbols, $\alpha[\sigma]$ denotes the result of attaching (coping) $[\sigma]$ to every nonterminal in $\alpha$.  Each production in $P$ takes one of the following forms:
\begin{align*}
A[\sigma] &\rightarrow \alpha[\sigma]\\
A[\sigma] & \rightarrow B[f\sigma]\\
A[f\sigma] & \rightarrow \alpha[\sigma]\\
\end{align*}




\subsection{Generating the Index Grammar}

Given a query $q(a,x)$, a set of path functions $F$, we explain how to translate them into index grammar rules. In what follows, all functions are supposed to be linear, with only one input.\\

The first thing to notice here is that, when a function $f = r_1 ... r_n$ is given, as it is possible to access all outputs, we can consider that we also have the subfunctions $f_1 = r_1$, $f_2 = r_1 r_2$, ..., $f_n = r_1 ... r_n$.\\

Why is it essential to have access to these subfunctions? Let's imagine we have a query $q$ but the only function given is $f = q \, a$. The algorithm we are going to present or a simple top-down approach might consider that too much information was generated and one needs to compensate the $a$ by an other function. With the subfunction $f' = q$, we do not have this problem.\\

So, from the set of path functions $F$, an other set of path functions can be generated which contains all the subfunction of functions in $F$. We call this new set $F'$.\\

We are going to use the functions from $F'$ to explore all possible combinations of functions $f_1 ... f_k$, with $f_1$, ..., $f_k$ in $F'$ such that $f_1 ... f_k = lq$ where $l$ is a way-back list. This way, we are going to obtain all possible smart plans for the query $q$.\\

Here, indexed grammars need to be introduced: one needs to remember which relations need to be compensate in order to create a correct way-back list. For example, if we call a function $f = a \, b \, c$, the relations $a^{-1}$, $b^{-1}$ and $c^{-1}$ will have to exist in the final result (except if $a$, $b$ or $c$ are part of the query). So, either functions created before $f$ were called to generate them or functions will have to generate them in the future. The relations which have to be created in the future are pushed on a stack, which is the stack used in indexed grammars.\\

Then, each function can be consumed in several ways. At a given moment, only a part of a function may be required. So, the rest of the function will have to be compensate in the future. In what follows, we will present the indexed grammar rules which represent these partial consumptions.


\subsection{Rules}

%\begin{Definition}[Left Rules]
%\label{leftrule}
%A left rule will consume the beginning of a function. Let $f=r_1...r_n$ be a linear function. We call left rules extracted from $f$ the production rules (for an indexed grammar):
%\begin{itemize}
%\item $C[r_1...r_n \sigma] \rightarrow r_1 ... r_n C[\sigma]$
%\item $C[r_1...r_{n-1} \sigma] \rightarrow r_1 ... r_n C[r_{n}^{-1} \sigma]$
%\item ...
%\item $C[r_1 \sigma] \rightarrow r_1 ... r_n C[r_{n}^{-1} ... r_2^{-1} \sigma]$
%\item $C[\sigma] \rightarrow r_1 ... r_n C[r_{n}^{-1} ... r_1^{-1} \sigma]$
%\end{itemize}
%where $\sigma$ represents the stack.
%\end{Definition}

%\begin{proof}
%These are allowed indexed grammar rules. See \ref{reducedleftrules}.
%\end{proof}

%\begin{Definition}[Right Rules]
%\label{rightrule}
%A right rule will consume the end of a function. Let $f=r_1...r_n$ be a linear function. We call right rules extracted from $f$ the production rules (for an indexed grammar):\\
%For all $i \in [2, n]$, $C[r_i...r_n \sigma] \rightarrow C[r_{i-1}^{-1} ... r_1^{-1}] r_1 ... r_n C[\sigma]$ \\
%and $C[\sigma] \rightarrow C[r_{n}^{-1} ... r_1^{-1}] r_1 ... r_n C[\sigma]$ \\
%where $\sigma$ represents the stack.
%\end{Definition}

%\begin{proof}
%These are allowed indexed grammar rules. See \ref{reducedrightrules}.
%\end{proof}

\begin{Definition}[Middle Rules]
\label{middleRule}
For a middle rule, the middle of a function is consumed and so, both the begin and the end are required to be completed in the future. Let $f=r_1...r_n$ be a linear function. We call middle rules extracted from $f$ the production rules (for an indexed grammar):\\
For all $ 1 \leq i \leq j \leq n + 1 $, we extract the rule:\\
$C[r_i ... r_j \sigma] \rightarrow C[r_{i-1}^{-1} ... r_1^{-1}]r_1 ... r_n C[r_n^{-1} ... r_{j+1}^{-1} \sigma]$ \\
where $\sigma$ represents the stack and $r_k$ is an empty relation if $k$ is not in $[1; n]$.
\end{Definition}

%\begin{proof}
%These are allowed indexed grammar rules. See \ref{reducedmiddlerules}.
%\end{proof}

\subsection{Example}

Let's suppose we have the function $f_1 = c \, c \, b$. Then, the generated rules will be:
\begin{itemize}
\item $C[c \, c \, b \, \sigma] = c \, c \, b \, C[\sigma]$
\item $C[c \, c \, \sigma] = c \, c \, b \, C[b^{-1} \, \sigma]$
\item $C[c \, \, \sigma] = c \, c \, b \, C[b^{-1} \, c^{-1} \, \sigma]$
\item $C[\sigma] = c \, c \, b \, C[b^{-1} \, c^{-1} \, c^{-1} \, \sigma]$
\item $C[\sigma] = C[b^{-1} \, c^{-1} \, c^{-1}] \, c \, c \, b \, C[\sigma]$
\item $C[b \, \sigma] = C[c^{-1} \, c^{-1}]\,  c \, c \, b \, C[\sigma]$
\item $C[b \, c \, \sigma] = C[c^{-1}]\,  c \, c \, b \, C[\sigma]$
\item $C[c \, \sigma] = C[c^{-1}]\,  c \, c \, b \, C[b^{-1} \, \sigma]$
\end{itemize}

Let's suppose we have the function $f_2 = c^{-1}$. Then, the generated rules will be:
\begin{itemize}
\item $C[c^{-1} \sigma] = c^{-1} \, C[\sigma]$
\item $C[\sigma] = c^{-1} \, C[c \, \sigma]$
\item $C[\sigma] = C[c] \, c^{-1} \, C[\sigma]$
\end{itemize} 

\subsection{Initialization Rule}

To initialize our indexed grammar, we need to add the following rules:
\begin{itemize}
\item $S \rightarrow C[q]$
\item $C[] \rightarrow \epsilon$
\end{itemize}
where $S$ is the starting non-terminal and $q$ is the query.
Then, for all functions, the middle rules described in definition \ref{middleRule} must be generated (the non-terminal $C$ is the same for all functions).

\subsection{Example}

Let's keep our previous functions $f_1 = c \, c \, b$ and $f_2 = c^{-1}$ and let's suppose we have the query $q = b$. A word can be found in the following way:

\begin{equation}
\begin{split}
C[b] & \rightarrow^{f_1} C[c^{-1} \, c^{-1}] \, c \, c \, b \, C[]\\
     & \rightarrow^{f_2} c^{-1} \, C[c^{-1}] \, c \, c \, b \, C[]\\
     & \rightarrow^{f_2} c^{-1} \, c^{-1} \, C[] \, c \, c \, b \, C[]\\
     & \rightarrow^{end} c^{-1} \, c^{-1} \, c \, c \, b\\
\end{split}
\end{equation}

So, a solution would be to call $f_2$ twice and then to call $f_1$.